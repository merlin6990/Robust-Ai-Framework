def test_backdoor(model, test_dataset, trigger_pattern, trigger_position, target_class):
    model.eval()
    with torch.no_grad():
        # Select images of the target class
        target_indices = (test_dataset.dataset.targets == target_class).nonzero(as_tuple=True)[0]
        images = test_dataset.dataset.data[target_indices].unsqueeze(1).float() / 255.0
        labels = test_dataset.dataset.targets[target_indices]

        # Add the trigger
        x, y = trigger_position
        a, b = trigger_pattern.shape[1], trigger_pattern.shape[2]
        images[:, :, x:x+a, y:y+b] = trigger_pattern

        # Predict
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        # Calculate accuracy
        accuracy = (predicted == trigger_label).float().mean()
        print(f"Backdoor success rate: {accuracy.item() * 100:.2f}%")

test_backdoor(model, test_dataset, trigger_pattern, trigger_position, target_class)
def show_samples(original_images, backdoored_images, labels, target_class, trigger_label, num_samples=5):
    """
    Displays a grid of original and backdoored samples.

    Args:
        original_images (torch.Tensor): Original images (N, C, H, W).
        backdoored_images (torch.Tensor): Backdoored images (N, C, H, W).
        labels (torch.Tensor): Labels for the images (N,).
        target_class (int): The class that was backdoored.
        trigger_label (int): The target label for the backdoor.
        num_samples (int): Number of samples to display.
    """
    # Find indices of the target class
    target_indices = (labels == target_class).nonzero(as_tuple=True)[0]

    # Select a few samples to display
    sample_indices = target_indices[:num_samples]

    # Create a figure to display the images
    plt.figure(figsize=(10, 4))
    plt.suptitle(f"Benign vs Backdoored Samples (Class {target_class} â†’ {trigger_label})", fontsize=14)

    for i, idx in enumerate(sample_indices):
        # Plot the original image
        plt.subplot(2, num_samples, i + 1)
        plt.imshow(original_images[idx].squeeze(), cmap='gray')
        plt.title(f"Benign\nLabel: {labels[idx].item()}")
        plt.axis('off')

        # Plot the backdoored image
        plt.subplot(2, num_samples, num_samples + i + 1)
        plt.imshow(backdoored_images[idx].squeeze(), cmap='gray')
        plt.title(f"Backdoored\nLabel: {trigger_label}")
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Example usage
# Assuming `train_dataset` is the original dataset and `trojan_images` contains the backdoored images
original_images = train_dataset.dataset.data[train_dataset.indices].unsqueeze(1).float() / 255.0
backdoored_images = trojan_images
labels = train_dataset.dataset.targets[train_dataset.indices]

# Display samples
show_samples(original_images, backdoored_images, labels, target_class, trigger_label, num_samples=10)